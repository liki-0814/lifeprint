import json
import logging
from datetime import date, timedelta
from typing import Optional

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_

from app.models.analysis import AnalysisResult, GrowthMetric
from app.models.media import MediaFile, MediaChild
from app.models.report import MonthlyReport
from app.config import settings

logger = logging.getLogger(__name__)


async def calculate_radar_data(
    db: AsyncSession, child_id: str, report_month: date
) -> dict:
    """è®¡ç®—æœˆåº¦é›·è¾¾å›¾æ•°æ®ï¼Œä» analysis_results èšåˆå„ç»´åº¦å¾—åˆ†"""
    month_start = report_month.replace(day=1)
    if month_start.month == 12:
        next_month = month_start.replace(year=month_start.year + 1, month=1)
    else:
        next_month = month_start.replace(month=month_start.month + 1)

    radar_data = {
        "interest": {"sport": 0.0, "music": 0.0, "art": 0.0, "learning": 0.0, "social": 0.0},
        "talent": {"logic": 0.0, "spatial": 0.0, "language": 0.0, "motor": 0.0},
        "psychology": {"empathy": 0.0, "resilience": 0.0, "confidence": 0.0},
    }

    media_ids_result = await db.execute(
        select(MediaFile.id)
        .join(MediaChild, MediaChild.media_id == MediaFile.id)
        .where(
            MediaChild.child_id == child_id,
            MediaFile.uploaded_at >= month_start,
            MediaFile.uploaded_at < next_month,
        )
    )
    media_ids = [row[0] for row in media_ids_result.all()]

    if not media_ids:
        return radar_data

    behavior_results = await db.execute(
        select(AnalysisResult).where(
            AnalysisResult.media_id.in_(media_ids),
            AnalysisResult.analysis_type == "behavior",
        )
    )
    behaviors = list(behavior_results.scalars().all())

    activity_counts: dict[str, int] = {}
    for behavior in behaviors:
        activities = behavior.result_data.get("activities", [])
        for activity in activities:
            activity_type = activity.get("type", "unknown")
            activity_counts[activity_type] = activity_counts.get(activity_type, 0) + 1

    total = max(sum(activity_counts.values()), 1)
    radar_data["interest"]["sport"] = activity_counts.get("sport", 0) / total
    radar_data["interest"]["music"] = activity_counts.get("music", 0) / total
    radar_data["interest"]["art"] = activity_counts.get("art", 0) / total
    radar_data["interest"]["learning"] = activity_counts.get("learning", 0) / total
    radar_data["interest"]["social"] = activity_counts.get("social", 0) / total

    cognition_results = await db.execute(
        select(AnalysisResult).where(
            AnalysisResult.media_id.in_(media_ids),
            AnalysisResult.analysis_type == "cognition",
        )
    )
    cognitions = list(cognition_results.scalars().all())

    if cognitions:
        avg_vocabulary = sum(
            c.result_data.get("vocabulary_richness", 0) for c in cognitions
        ) / len(cognitions)
        avg_complexity = sum(
            c.result_data.get("sentence_complexity", 0) for c in cognitions
        ) / max(len(cognitions), 1)
        radar_data["talent"]["language"] = min(avg_vocabulary, 1.0)
        radar_data["talent"]["logic"] = min(avg_complexity / 5.0, 1.0)

    emotion_results = await db.execute(
        select(AnalysisResult).where(
            AnalysisResult.media_id.in_(media_ids),
            AnalysisResult.analysis_type == "emotion",
        )
    )
    emotions = list(emotion_results.scalars().all())

    if emotions:
        positive_count = sum(
            1 for e in emotions
            if e.result_data.get("dominant") in ("happy", "calm", "excited")
        )
        radar_data["psychology"]["confidence"] = positive_count / len(emotions)
        radar_data["psychology"]["resilience"] = min(len(emotions) / 30.0, 1.0)

    return radar_data


async def detect_spark_cards(db: AsyncSession, child_id: str) -> list[dict]:
    """æ£€æµ‹è¿ç»­ 3 ä¸ªæœˆçš„é«˜ä¸“æ³¨è¡Œä¸ºï¼Œç”Ÿæˆç«èŠ±å¡ç‰‡"""
    spark_cards = []

    metrics_result = await db.execute(
        select(GrowthMetric)
        .where(
            GrowthMetric.child_id == child_id,
            GrowthMetric.metric_type.in_(["focus_logic", "focus_spatial", "focus_language", "focus_motor"]),
        )
        .order_by(GrowthMetric.measured_at.desc())
        .limit(120)
    )
    metrics = list(metrics_result.scalars().all())

    metric_by_type: dict[str, list[GrowthMetric]] = {}
    for metric in metrics:
        metric_by_type.setdefault(metric.metric_type, []).append(metric)

    talent_names = {
        "focus_logic": "é€»è¾‘æ¨ç†",
        "focus_spatial": "ç©ºé—´æƒ³è±¡",
        "focus_language": "è¯­è¨€è¡¨è¾¾",
        "focus_motor": "è¿åŠ¨åè°ƒ",
    }

    for metric_type, metric_list in metric_by_type.items():
        high_focus_months = sum(1 for m in metric_list if m.metric_value >= 0.7)
        if high_focus_months >= 3:
            talent_name = talent_names.get(metric_type, metric_type)
            avg_score = sum(m.metric_value for m in metric_list) / len(metric_list)
            spark_cards.append({
                "talent": metric_type.replace("focus_", ""),
                "talent_name": talent_name,
                "confidence": round(avg_score, 2),
                "months_detected": high_focus_months,
                "suggestion": f"å­©å­åœ¨{talent_name}æ–¹é¢è¡¨ç°å‡ºæŒç»­çš„é«˜ä¸“æ³¨åº¦ï¼Œå»ºè®®æä¾›æ›´å¤šç›¸å…³çš„å­¦ä¹ å’Œæ¢ç´¢æœºä¼šã€‚",
            })

    return spark_cards


async def generate_monthly_summary(
    radar_data: dict, spark_cards: list[dict]
) -> str:
    """ä½¿ç”¨ç»Ÿä¸€ LLM client ç”Ÿæˆæœˆåº¦æˆé•¿æ€»ç»“"""
    import time as _time
    from app.ai.remote.llm_client import get_llm_client

    logger.info("ğŸ“ [æœˆåº¦æ€»ç»“] å¼€å§‹ç”Ÿæˆæœˆåº¦æˆé•¿æ€»ç»“ï¼Œç«èŠ±å¡ç‰‡æ•°=%d", len(spark_cards))

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å„¿ç«¥å‘å±•é¡¾é—®ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®ï¼Œä¸ºå®¶é•¿æ’°å†™ä¸€ä»½æ¸©æš–ã€é¼“åŠ±æ€§çš„æœˆåº¦æˆé•¿æ€»ç»“ï¼ˆ200-300å­—ï¼‰ã€‚

å…´è¶£åå¥½åˆ†å¸ƒï¼š
- è¿åŠ¨: {radar_data['interest']['sport']:.0%}
- éŸ³ä¹: {radar_data['interest']['music']:.0%}
- è‰ºæœ¯: {radar_data['interest']['art']:.0%}
- å­¦ä¹ : {radar_data['interest']['learning']:.0%}
- ç¤¾äº¤: {radar_data['interest']['social']:.0%}

å¤©èµ‹æŒ‡æ ‡ï¼š
- é€»è¾‘æ¨ç†: {radar_data['talent']['logic']:.0%}
- ç©ºé—´æƒ³è±¡: {radar_data['talent']['spatial']:.0%}
- è¯­è¨€è¡¨è¾¾: {radar_data['talent']['language']:.0%}
- è¿åŠ¨åè°ƒ: {radar_data['talent']['motor']:.0%}

å¿ƒç†ç‰¹è´¨ï¼š
- åŒç†å¿ƒ: {radar_data['psychology']['empathy']:.0%}
- æŠ—æŒ«åŠ›: {radar_data['psychology']['resilience']:.0%}
- è‡ªä¿¡å¿ƒ: {radar_data['psychology']['confidence']:.0%}

å‘ç°çš„å¤©èµ‹ç«èŠ±ï¼š{len(spark_cards)} ä¸ª
{chr(10).join(f"- {card['talent_name']}ï¼ˆç½®ä¿¡åº¦ {card['confidence']:.0%}ï¼‰" for card in spark_cards) if spark_cards else "æš‚æ— "}

è¯·ç”¨ç¬¬äºŒäººç§°ï¼ˆ"æ‚¨çš„å­©å­"ï¼‰æ’°å†™ï¼Œè¯­æ°”æ¸©æš–ç§¯æï¼Œçªå‡ºè¿›æ­¥å’Œäº®ç‚¹ã€‚"""

    try:
        client = get_llm_client()
        start_time = _time.time()
        result = await client.chat(prompt=prompt)
        elapsed = _time.time() - start_time
        logger.info("ğŸ“ [æœˆåº¦æ€»ç»“] ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶=%.1fsï¼Œå†…å®¹é•¿åº¦=%då­—ç¬¦", elapsed, len(result))
        return result
    except Exception as error:
        logger.warning("âŒ [æœˆåº¦æ€»ç»“] LLM ç”Ÿæˆå¤±è´¥: %sï¼Œä½¿ç”¨é»˜è®¤æ–‡æ¡ˆ", error, exc_info=True)

    return "æœ¬æœˆå­©å­è¡¨ç°è‰¯å¥½ï¼Œå„æ–¹é¢éƒ½åœ¨ç¨³æ­¥æˆé•¿ã€‚ç»§ç»­ä¿æŒå¯¹å­©å­çš„å…³æ³¨å’Œé™ªä¼´ï¼Œè®©æˆé•¿çš„æ¯ä¸€æ­¥éƒ½è¢«æ¸©æŸ”è®°å½•ã€‚"


def _flatten_radar_data(radar_data: dict) -> list[dict]:
    """å°†åµŒå¥—çš„ radar_data dict è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„ array æ ¼å¼"""
    dimension_labels = {
        "interest": {
            "sport": "è¿åŠ¨", "music": "éŸ³ä¹", "art": "è‰ºæœ¯",
            "learning": "å­¦ä¹ ", "social": "ç¤¾äº¤",
        },
        "talent": {
            "logic": "é€»è¾‘æ¨ç†", "spatial": "ç©ºé—´æƒ³è±¡",
            "language": "è¯­è¨€è¡¨è¾¾", "motor": "è¿åŠ¨åè°ƒ",
        },
        "psychology": {
            "empathy": "åŒç†å¿ƒ", "resilience": "æŠ—æŒ«åŠ›",
            "confidence": "è‡ªä¿¡å¿ƒ",
        },
    }
    flat_list = []
    for category, dimensions in dimension_labels.items():
        category_data = radar_data.get(category, {})
        for key, label in dimensions.items():
            score = category_data.get(key, 0.0)
            flat_list.append({
                "dimension": label,
                "score": round(score * 100, 1),
            })
    return flat_list


async def generate_report_sync(child_id: str, db: AsyncSession) -> None:
    """åœ¨æ—  Celery ç¯å¢ƒä¸‹ç›´æ¥åŒæ­¥ç”Ÿæˆæœˆåº¦æŠ¥å‘Š"""
    import time as _time
    from app.models.child import Child
    from app.ai.remote.report_generator import generate_growth_narrative

    logger.info("ğŸš€ [æŠ¥å‘Šç”Ÿæˆ] å¼€å§‹åŒæ­¥ç”Ÿæˆæœˆåº¦æŠ¥å‘Šï¼Œchild_id=%s", child_id)
    overall_start = _time.time()

    report_month = date.today().replace(day=1)

    child_result = await db.execute(
        select(Child).where(Child.id == child_id)
    )
    child = child_result.scalar_one_or_none()
    if not child:
        logger.error("âŒ [æŠ¥å‘Šç”Ÿæˆ] å­©å­ä¸å­˜åœ¨: %s", child_id)
        raise ValueError(f"å­©å­ä¸å­˜åœ¨: {child_id}")

    existing = await db.execute(
        select(MonthlyReport).where(
            MonthlyReport.child_id == child_id,
            MonthlyReport.report_month == report_month,
        )
    )
    if existing.scalar_one_or_none():
        logger.info("â­ï¸ [æŠ¥å‘Šç”Ÿæˆ] æœ¬æœˆæŠ¥å‘Šå·²å­˜åœ¨ï¼Œè·³è¿‡: child_id=%s, month=%s", child_id, report_month)
        return

    logger.info("ğŸ“ˆ [æŠ¥å‘Šç”Ÿæˆ] æ­¥éª¤1: è®¡ç®—é›·è¾¾å›¾æ•°æ®...")
    radar_data = await calculate_radar_data(db, child_id, report_month)
    logger.info("ğŸ“ˆ [æŠ¥å‘Šç”Ÿæˆ] é›·è¾¾å›¾æ•°æ®è®¡ç®—å®Œæˆ: %s", json.dumps(radar_data, ensure_ascii=False)[:300])

    logger.info("ğŸ”¥ [æŠ¥å‘Šç”Ÿæˆ] æ­¥éª¤2: æ£€æµ‹å¤©èµ‹ç«èŠ±å¡ç‰‡...")
    spark_cards = await detect_spark_cards(db, child_id)
    logger.info("ğŸ”¥ [æŠ¥å‘Šç”Ÿæˆ] æ£€æµ‹åˆ° %d ä¸ªç«èŠ±å¡ç‰‡", len(spark_cards))

    age_months = (
        (report_month.year - child.birth_date.year) * 12
        + report_month.month - child.birth_date.month
    )

    logger.info("ğŸ“Š [æŠ¥å‘Šç”Ÿæˆ] æ­¥éª¤3: è°ƒç”¨ LLM ç”Ÿæˆæˆé•¿å™äº‹...")
    narrative = await generate_growth_narrative(
        child_name=child.name,
        age_months=age_months,
        radar_data=radar_data,
        spark_cards=spark_cards,
        behavior_summary=[],
        emotion_summary={},
    )

    logger.info("ğŸ“ [æŠ¥å‘Šç”Ÿæˆ] æ­¥éª¤4: è°ƒç”¨ LLM ç”Ÿæˆæœˆåº¦æ€»ç»“...")
    summary = await generate_monthly_summary(radar_data, spark_cards)

    report = MonthlyReport(
        child_id=child_id,
        report_month=report_month,
        summary_text=summary,
        radar_data=radar_data,
        spark_cards=spark_cards,
        narrative=narrative,
    )
    db.add(report)
    await db.commit()

    overall_elapsed = _time.time() - overall_start
    logger.info("âœ… [æŠ¥å‘Šç”Ÿæˆ] æœˆåº¦æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼child_id=%s, æ€»è€—æ—¶=%.1fs", child_id, overall_elapsed)
